{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"softmax.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"b6cDWrxHo05H","colab_type":"text"},"source":["### Problems with squared error when training a neural networks\n",">-If the desired output is 1 and the actual output is 0.00000001 there is almost no gradient for logistic unit to fix up the error(change). eg: when on plateaux slow is almost horizontal(0). \n","### Is there a different cost function that works better? \n","### The Softmax Function:\n","\n",">$x = \\{0,0,0,0,0,0,0,0,...0\\}^N$\n","\n",">$y_i=\\frac{e^{x_i}}{\\sum_{j\\in{group}}{e^{x_j}}}$\n","\n",">We can interpret it as a probability distribution.\n","\n","### Derivative of softmax function:\n",">$\\frac{\\partial{y_i}}{\\partial{x_i}}=y_i(1-y_i)$\n","\n","### Problems with softmax:\n",">**Overflow:** When x is too large sofxmax is inf\n","\n",">**Underflow:** When x is too small softmax is zero\n","\n",">**Fix:** Use $(x-\\max_i{(x_i)})$ instead of $x_i$\n","\n",">>$y_i=\\frac{e^{(x-\\max_i{(x_i)})}}{\\sum_{j\\in{group}}{e^{(x-\\max_i{(x_i)})}}}$\n","\n","\n","### So what is the right cost function to use with softmax? (multiclass classification)\n","\n",">$C = -\\sum_{j}{t_jlogy_j}$\n","\n",">where $t_j$ is the target value.\n","\n",">It is the negative llog probability of the right answer\n","\n",">It's called **cross-entropy**\n","\n",">E.g: C has a very big gradient when the target value is 1 and the output is almost zero\n","\n","[Video(Hinton)](https://www.youtube.com/watch?v=mlaLLQofmR8&t=10s)\n","\n","[VIdeo(Ng)](https://www.youtube.com/watch?v=LLux1SW--oM)"]},{"cell_type":"code","metadata":{"id":"LNMsHHRToky3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b434c506-babb-4500-bbfe-9c460427d9ff","executionInfo":{"status":"ok","timestamp":1560883184252,"user_tz":180,"elapsed":441,"user":{"displayName":"tianye wang","photoUrl":"https://lh6.googleusercontent.com/-Mx2x3Dd5gPA/AAAAAAAAAAI/AAAAAAAAAOQ/sqYzqu602T8/s64/photo.jpg","userId":"12454609316683315269"}}},"source":["import numpy as np\n","\n","x = np.random.rand(5)\n","print(x)"],"execution_count":62,"outputs":[{"output_type":"stream","text":["[0.81245063 0.71863571 0.19172764 0.33516107 0.40421493]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wTaTo1P51387","colab_type":"text"},"source":["###Softmax:"]},{"cell_type":"code","metadata":{"id":"qGkd77_pt9Ba","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"38d68307-6e92-4f19-b9e1-39da8bdb3c23","executionInfo":{"status":"ok","timestamp":1560883184408,"user_tz":180,"elapsed":299,"user":{"displayName":"tianye wang","photoUrl":"https://lh6.googleusercontent.com/-Mx2x3Dd5gPA/AAAAAAAAAAI/AAAAAAAAAOQ/sqYzqu602T8/s64/photo.jpg","userId":"12454609316683315269"}}},"source":["def softmax(x):\n","  softmax = np.exp(x)/np.sum(np.exp(x))\n","  return softmax\n","\n","print(softmax(x))\n","print(\"check sum:\",sum(softmax(x)))"],"execution_count":63,"outputs":[{"output_type":"stream","text":["[0.26786012 0.24387358 0.14398972 0.16619725 0.17807934]\n","check sum: 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"572PUrE916zE","colab_type":"text"},"source":["### Stable Softmax:"]},{"cell_type":"code","metadata":{"id":"XkoYlkN90FUw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"cb3b5630-8e5a-4425-c84a-d460f1d6216b","executionInfo":{"status":"ok","timestamp":1560883981157,"user_tz":180,"elapsed":329,"user":{"displayName":"tianye wang","photoUrl":"https://lh6.googleusercontent.com/-Mx2x3Dd5gPA/AAAAAAAAAAI/AAAAAAAAAOQ/sqYzqu602T8/s64/photo.jpg","userId":"12454609316683315269"}}},"source":["def stable_softmax(x):\n","  tmp = x-np.max(x)\n","  softmax = np.exp(tmp)/np.sum(np.exp(tmp))\n","  return softmax\n","\n","x = np.random.rand(5)+100000\n","\n","#Compare the two\n","print(softmax(x))\n","print(\"check\",sum(softmax(x)))\n","\n","print(stable_softmax(x))\n","print(\"check sum:\",sum(stable_softmax(x)))"],"execution_count":85,"outputs":[{"output_type":"stream","text":["[nan nan nan nan nan]\n","check nan\n","[0.24745667 0.16267377 0.26770832 0.19848325 0.12367799]\n","check sum: 1.0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"iUQSwFbh3ZTo","colab_type":"code","colab":{}},"source":["def cross_entropy(X,t):\n","    y = stable_softmax(X)\n","    #fro two class\n","    loss = -np.sum(t*np.log(y)+(1-t)*np.log(1-y))\n","    #loss = -np.sum(t*np.log(y))\n","    return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vug_P1096VnQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"63661e00-063d-4a92-863e-8d70080474f6","executionInfo":{"status":"ok","timestamp":1560884671305,"user_tz":180,"elapsed":381,"user":{"displayName":"tianye wang","photoUrl":"https://lh6.googleusercontent.com/-Mx2x3Dd5gPA/AAAAAAAAAAI/AAAAAAAAAOQ/sqYzqu602T8/s64/photo.jpg","userId":"12454609316683315269"}}},"source":["#compare implimentations in sklearn\n","from sklearn.metrics import log_loss\n","\n","t = np.random.randint(2, size=5)\n","print(cross_entropy(x,t))\n","\n","print(\"sklearn:\",log_loss(t,stable_softmax(x),normalize = False))"],"execution_count":132,"outputs":[{"output_type":"stream","text":["6.1190060844735585\n","sklearn: 6.1190060844735585\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ngxMGU9z6hCm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}